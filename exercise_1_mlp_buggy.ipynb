{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x129c77790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Learning point: understand basic PyTorch concepts and how to train a simple MLP model\n",
    "\n",
    "\"\"\"\n",
    "Task:  fix this buggy code in the code\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  \n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 511),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # breakpoint()\n",
    "        # Flatten the image for the input layer\n",
    "        x = self.flatten(x)\n",
    "        # Apply the linear layers of MLP with ReLU activation\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        # Apply the softmax function to get probabilities\n",
    "        probabilities = self.softmax(logits)\n",
    "        return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  \n",
    "# Load MNIST dataset\n",
    "# Import to rescale the image to [-1, 1] to match activation functions\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  \n",
    "# Prepare the dataloaders, shuffle the data, and set the batch size\n",
    "# Batches are used to update the model weights because we can't pass the entire dataset at once\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#%%  \n",
    "# Initialize the model\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28]) Class: 5\n"
     ]
    }
   ],
   "source": [
    "#%%  \n",
    "# MNIST dataset\n",
    "test_tensor = train_data[0]\n",
    "print(\"Image shape:\", test_tensor[0].shape, \"Class:\", test_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test model forward pass\n"
     ]
    }
   ],
   "source": [
    "#%%  \n",
    "print(\"Test model forward pass\")\n",
    "assert model(test_tensor[0]).shape == (1, 10), \"Model output shape is incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  \n",
    "learning_rate = 1e-3\n",
    "epochs = 25\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: -53.159641, Progress: [0/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [6400/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [12800/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [19200/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [25600/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [32000/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [38400/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [44800/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [51200/60000]\n",
      "Epoch: 1, Loss: nan, Progress: [57600/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 1/25 [00:13<05:32, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: nan, Progress: [0/60000]\n",
      "Epoch: 2, Loss: nan, Progress: [6400/60000]\n",
      "Epoch: 2, Loss: nan, Progress: [12800/60000]\n",
      "Epoch: 2, Loss: nan, Progress: [19200/60000]\n",
      "Epoch: 2, Loss: nan, Progress: [25600/60000]\n",
      "Epoch: 2, Loss: nan, Progress: [32000/60000]\n"
     ]
    }
   ],
   "source": [
    "#%% Training \n",
    "for epoch in tqdm(range(epochs)):\n",
    "    size = len(train_dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, pred)\n",
    "\n",
    "        # Clear old gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute derivatives\n",
    "        loss.backward()\n",
    "        # Update the weights of the model using the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Epoch: {epoch+1}, Loss: {loss:.6f}, Progress: [{current}/{size}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  \n",
    "# Test the model\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# Disable gradient computation for evaluation to save memory and computations\n",
    "with torch.no_grad():\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for X, y in test_dataloader:\n",
    "        # breakpoint()\n",
    "        preds = model(X)\n",
    "        all_preds.extend(preds.argmax(1).numpy())  # Get the predicted classes\n",
    "        all_labels.extend(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  \n",
    "# Convert list to NumPy arrays for Scikit-Learn\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  \n",
    "# Classification report\n",
    "report = classification_report(\n",
    "    all_labels, all_preds, target_names=[str(i) for i in range(10)]\n",
    ")\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
